# OPENAI, AZURE, OPENROUTER, ANTHROPIC, LITELLM or LMSTUDIO
ENDPOINT=LITELLM

#LITELLM
ENDPOINT_URL=http://0.0.0.0:4000/chat/completions
API_KEY=anything
MODEL_NAME=openai/gpt-4-turbo

#LMSTUDIO
#ENDPOINT_URL=http://localhost:1234/v1/chat/completions
#API_KEY=anything
#MODEL_NAME=openai/gpt-4-turbo


#OPENROUTER
#ENDPOINT_URL=https://openrouter.ai/api/v1/chat/completions
#API_KEY=
#MODEL_NAME=openai/gpt-4-turbo

#OPENAI
#ENDPOINT_URL=https://api.openai.com/v1/chat/completions
#API_KEY=
#MODEL_NAME=openai/gpt-4-turbo



# In case of Anthropic, use "anthropic/" + the model name, example for Claude 3 Opus
# MODEL_NAME=anthropic/claude-3-opus-20240229
MAX_TOKENS=8192

# Folders which shouldn't be tracked in workspace (useful to ignore folders created by compiler)
IGNORE_PATHS=geeks

# Database
# DATABASE_TYPE=postgres

DB_NAME=gpt-pilot
DB_HOST=
DB_PORT=
DB_USER=
DB_PASSWORD=

# USE_GPTPILOT_FOLDER=true

# Load database imported from another location/system - EXPERIMENTAL
# AUTOFIX_FILE_PATHS=false

# Set extra buffer to wait on top of detected retry time when rate limmit is hit. defaults to 6
# RATE_LIMIT_EXTRA_BUFFER=
